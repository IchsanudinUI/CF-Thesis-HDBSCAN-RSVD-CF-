{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab422de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df_books = pd.read_excel(\"Skripsi/Dataset rapih 4sheet_skripsi_revisi.xlsx\",sheet_name=\"Gabungan\")\n",
    "\n",
    "df_books = pd.read_excel(\"/content/drive/MyDrive/Folder Skripsi CF_buku/Dataset rapih 4sheet_skripsi_revisi_cuma 1 sheet.xlsx\",\n",
    "                         sheet_name=\"15tahun\")\n",
    "df_books.dropna(axis=0, how=\"any\")\n",
    "df_user = pd.read_excel(\"/content/drive/MyDrive/Folder Skripsi CF_buku/User_skripsi.xlsx\", sheet_name=\"GabunganU\")#GabunganU, sheet sampe 7\n",
    "df_user['Rating'] = df_user['Rating'].replace(['it was amazing', 'really liked it', \"liked it\",\\\n",
    "                                               \"did not like it\",\"it was ok\",\"This user doesn't have any rating\"],\\\n",
    "                                              [5, 4, 3,1,2,0])\n",
    "df_user = df_user.dropna(axis=0, how='any')\n",
    "\n",
    "df_books[\"Name\"] = df_books[\"Name\"].astype(str)\n",
    "df_user[\"Name\"] = df_user[\"Name\"].astype(str)\n",
    "\n",
    "df_user.drop(df_user.index[df_user['Rating'] == 0], inplace=True)\n",
    "\n",
    "df_books['RatingDistTotal'] = df_books['RatingDistTotal'].\\\n",
    "astype('str').str.extractall('(\\d+)').unstack().fillna('').sum(axis=1).astype(int)\n",
    "\n",
    "df_books_eval_replace = df_books[[\"RatingDist1\", \"RatingDist2\", \"RatingDist3\", \"RatingDist4\", \"RatingDist5\"]]\n",
    "list_nama_column_eval_replace = [\"RatingDist1\", \"RatingDist2\", \"RatingDist3\", \"RatingDist4\", \"RatingDist5\"]\n",
    "\n",
    "for i in range(5):\n",
    "    df_books_eval_replace[\n",
    "        list_nama_column_eval_replace[i]] = df_books_eval_replace[\n",
    "            list_nama_column_eval_replace[i]].astype(str)\n",
    "    df_books_eval_replace[\n",
    "        list_nama_column_eval_replace[i]] = df_books_eval_replace[\n",
    "            list_nama_column_eval_replace[i]].str.replace(':','/')\n",
    "\n",
    "for i in range(5):\n",
    "    substitute_column = []\n",
    "    for j in range(len(df_books_eval_replace)):\n",
    "        if type(df_books_eval_replace.iloc[:, i][j]) == str:\n",
    "            substitute_column.append(eval(df_books_eval_replace.iloc[:, i][j]))\n",
    "        else:\n",
    "            substitute_column.append(df_books_eval_replace.iloc[:, i].loc[j])\n",
    "    df_books[list_nama_column_eval_replace[i]] = substitute_column\n",
    "\n",
    "df_books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dae168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_inner=df_user.merge(df_books, left_on='Name', right_on='Name', how='inner')\n",
    "\n",
    "df_merge_inner_pivot=df_merge_inner.pivot_table(index='ID', columns='Name', values='Rating_x')\n",
    "df_merge_inner_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5b316",
   "metadata": {},
   "source": [
    "# HDBSCAN-RSVD-CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beba079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vektor adalah perwakilan titik\n",
    "import hdbscan\n",
    "\n",
    "clusterer_user = hdbscan.HDBSCAN(min_cluster_size=2,min_samples=1,gen_min_span_tree=True)\n",
    "\n",
    "clusterer_user.fit(df_merge_inner_pivot.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f20a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sesi Cross Val\n",
    "import math\n",
    "urutan_list_bagi_5 = []\n",
    "for i in range(5):\n",
    "    urutan_list_bagi_5.append(\n",
    "            df_merge_inner_pivot.iloc[math.ceil((i)*20 / 100 *\n",
    "                                                len(df_merge_inner_pivot)):(i+1) *\n",
    "                                      math.ceil(20 / 100 *\n",
    "                                                len(df_merge_inner_pivot)), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_inner_pivot[\"user_cluster\"]=clusterer_user.labels_\n",
    "df_merge_inner_pivot=df_merge_inner_pivot.dropna(axis=1,how='all')\n",
    "df_merge_inner_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a89d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisi ke-3 7-6-2023\n",
    "#modifikasinya buat split test\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import math\n",
    "\n",
    "#inisiasi\n",
    "start_time = time.time()\n",
    "\n",
    "mean_dari_mean_rmse_kuintil=[]\n",
    "panjang_kumpulan_rmse_kuintil=[]\n",
    "kumpulan_dari_kumpulan_waktu_kuintil=[]\n",
    "\n",
    "list_matrixU_rsvd = []\n",
    "\n",
    "#Proses RSVD + Similarity\n",
    "#jika di cluster lebih dari 10 orang, maka dilakukan pemotongan\n",
    "for poke in range(df_merge_inner_pivot[\"user_cluster\"].max() + 2):\n",
    "    if len(df_merge_inner_pivot.groupby(\"user_cluster\").get_group(poke -\n",
    "                                                                  1)) >= 10:\n",
    "        U, s, Vh = randomized_svd(\n",
    "            df_merge_inner_pivot.groupby(\"user_cluster\").get_group(\n",
    "                poke - 1).drop(columns='user_cluster').fillna(0),\n",
    "            n_components=math.ceil(\n",
    "                len(\n",
    "                    df_merge_inner_pivot.groupby(\"user_cluster\").get_group(\n",
    "                        poke - 1).drop(columns='user_cluster').fillna(0)) *\n",
    "                80 / 100),random_state=0)   #80 bisa diganti sesuai keinginan pengambilan n-component\n",
    "\n",
    "        df_pivot_avg_rsvd_U = pd.DataFrame(U)\n",
    "        df_pivot_avg_rsvd_U = df_pivot_avg_rsvd_U.set_index(\n",
    "            df_merge_inner_pivot.groupby(\"user_cluster\").get_group(\n",
    "                poke - 1).drop(columns='user_cluster').fillna(0).index)\n",
    "        df_pivot_avg_rsvd_U = df_pivot_avg_rsvd_U.T.corr()\n",
    "        list_matrixU_rsvd.append(df_pivot_avg_rsvd_U)\n",
    "\n",
    "    else:\n",
    "        U, s, Vh = randomized_svd(\n",
    "            df_merge_inner_pivot.groupby(\"user_cluster\").get_group(poke-1).drop(\n",
    "                columns='user_cluster').fillna(0),\n",
    "            n_components=len(df_merge_inner_pivot.groupby(\"user_cluster\").\\\n",
    "                             get_group(poke-1).drop(columns='user_cluster')),random_state=0)\n",
    "\n",
    "        df_pivot_avg_rsvd_U = pd.DataFrame(U)\n",
    "        df_pivot_avg_rsvd_U = df_pivot_avg_rsvd_U.set_index(\n",
    "            df_merge_inner_pivot.groupby(\"user_cluster\").get_group(\n",
    "                poke - 1).drop(columns='user_cluster').fillna(0).index)\n",
    "        df_pivot_avg_rsvd_U = df_pivot_avg_rsvd_U.T.corr()\n",
    "        list_matrixU_rsvd.append(df_pivot_avg_rsvd_U)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "w_awal=(time.time() - start_time)\n",
    "\n",
    "#Prediksi rating buku oleh pengguna pada model HDBSCAN-RSVD-CF\n",
    "for kuintil in range(5):\n",
    "    picked_userid = urutan_list_bagi_5[kuintil].index\n",
    "    kumpulan_rmse = []\n",
    "    for i in range(len(picked_userid))\n",
    "        user_active_cluster = df_merge_inner_pivot.loc[picked_userid[i]][\"user_cluster\"]\n",
    "        user_similarity = list_matrixU_rsvd[int(user_active_cluster)+1]\n",
    "\n",
    "        # no 1\n",
    "        #Kegunaan T disini supaya dia transpose dan si Index itu yang kita Pearson\n",
    "\n",
    "        #========================================================================\n",
    "        # Variabel hapus pengguna aktif (data testing)\n",
    "        remove_user=user_similarity[user_similarity.index.isin(picked_userid)].index\n",
    "        # Hapus data testing supaya pemilihan korelasi Pearson tidak muncul dirinya sendiri\n",
    "        user_similarity = user_similarity.drop(index=remove_user)\n",
    "        #========================================================================\n",
    "        # Parameter batas similarity\n",
    "        user_similarity_threshold = 0.4\n",
    "        # mencari orang-orang yang memiliki nilai similarity >= 0.4\n",
    "        similar_users = user_similarity[\n",
    "            user_similarity[picked_userid[i]] > user_similarity_threshold][\n",
    "                picked_userid[i]].sort_values(ascending=False)\n",
    "        # Print daftar pengguna yang mirip dengna pengguna aktif\n",
    "        print(f'Proses n=10:\\nThe similar users for user {picked_userid[i]} are',\n",
    "              similar_users)\n",
    "\n",
    "        #========================================================================\n",
    "        # no 2\n",
    "        # Buku buku yang sudah dibaca oleh pengguna aktif\n",
    "        picked_userid_watched = df_merge_inner_pivot.\\\n",
    "        drop(columns=\"user_cluster\")[df_merge_inner_pivot.drop(columns=\"user_cluster\").\\\n",
    "                                     index == picked_userid[i]].dropna(axis=1, how='all')\n",
    "\n",
    "        # Menyesuaikan buku pengguna tak aktif dengan pengguna aktif\n",
    "        similar_user_buku = df_merge_inner_pivot.\\\n",
    "        drop(columns=\"user_cluster\")[df_merge_inner_pivot.drop(columns=\"user_cluster\").\\\n",
    "                                     index.isin(similar_users.index)].dropna(axis=1, how='all')\n",
    "        #========================================================================\n",
    "\n",
    "        #3\n",
    "        # membangun prediksi rating buku [sum (similarity * selisih rating pengguna tak aktif)/sum similiartiy] Perhatikan paper Geetha/skripsi\n",
    "        item_score = {}\n",
    "        # Looping buku\n",
    "        for j in similar_user_buku.columns:\n",
    "            # rating dari 1 buku (nanti iterasi)\n",
    "            buku_rating = similar_user_buku[j]\n",
    "            # total sebagai vairaibel dari prediksi bagian (similarity * selisih rating pengguna tak aktif)\n",
    "            total = 0\n",
    "            #tambahin mean di sini, nanti tinggal kurangin deh untuk si selisih rating pengguna tak aktif\n",
    "            mean_rating_user_u = buku_rating.mean()\n",
    "\n",
    "            # Proses looping pembentukan [sum (similarity * selisih rating pengguna tak aktif)/sum similiartiy] dari tiap pengguna serupa\n",
    "            for u in similar_users.index:\n",
    "                # fungsi if untuk mendanakan kalau si buku punya rating/tidak kosong\n",
    "                if pd.isna(buku_rating[u]) == False:\n",
    "                    # nilai dari (similarity * selisih rating pengguna tak aktif)\n",
    "                    score = similar_users[u] * abs(buku_rating[u] -\n",
    "                                                   mean_rating_user_u)\n",
    "                    # tambahin terus totalnya, karena sum\n",
    "                    total += score\n",
    "\n",
    "            # ini hasil akhir dari [sum (similarity * selisih rating pengguna tak aktif)/sum similiartiy] tetapi untuk 1 buku\n",
    "            item_score[j] = total / sum(similar_users)\n",
    "        # konversi dictionary jadi pandas df\n",
    "        item_score = pd.DataFrame(item_score.items(),\n",
    "                                  columns=['books', 'books_score'])\n",
    "\n",
    "        # sorting niali buku\n",
    "        ranked_item_score = item_score.sort_values(by='books_score',\n",
    "                                                   ascending=False)\n",
    "        #========================================================================\n",
    "        #4\n",
    "        # bagian rata-rata penialain buku oleh pengguna aktif dari prediksi rating buku\n",
    "        avg_rating = picked_userid_watched[picked_userid_watched.index ==\n",
    "                                           picked_userid[i]].T.mean()[\n",
    "                                               picked_userid[i]]\n",
    "        # print average penilaian buku si pengguna aktif\n",
    "        print(\n",
    "            f'The average books rating for user {picked_userid[i]} is {avg_rating:.2f}'\n",
    "        )\n",
    "\n",
    "        # Kalkulasi prediksi rating bukunya berdasarkan hasil yang didapat di proses-proses atas\n",
    "        ranked_item_score_plus_avg_rating = []\n",
    "\n",
    "        for k in range(len(ranked_item_score)):\n",
    "            if (ranked_item_score['books_score'][k] + avg_rating) >= 5:\n",
    "                ranked_item_score_plus_avg_rating.append(5)\n",
    "            else:\n",
    "                ranked_item_score_plus_avg_rating.append(\n",
    "                    ranked_item_score['books_score'][k] + avg_rating)\n",
    "\n",
    "        ranked_item_score['predicted_rating'] = ranked_item_score_plus_avg_rating\n",
    "\n",
    "        ranked_item_score.sort_values(by=[\"predicted_rating\"],\n",
    "                                      inplace=True,\n",
    "                                      ascending=False)\n",
    "        #========================================================================\n",
    "        #RMSE\n",
    "        #Kasus Geetha--sederhana\n",
    "        user_active_picked = picked_userid_watched.T\n",
    "\n",
    "        CF_model = ranked_item_score[ranked_item_score[\"books\"].isin(\n",
    "            user_active_picked.index[:])]\n",
    "        CF_model = CF_model.sort_values(by=['books'])\n",
    "\n",
    "\n",
    "        user_active_picked = user_active_picked[user_active_picked.T.columns.isin(\n",
    "            CF_model[\"books\"])]\n",
    "        user_active_picked = user_active_picked.sort_index()\n",
    "\n",
    "        #Hasil Geetha, user active\n",
    "\n",
    "        if len(user_active_picked.iloc[:, 0]) != 0 and len(\n",
    "                CF_model[\"predicted_rating\"]) != 0:\n",
    "            rms = sqrt(\n",
    "                mean_squared_error(user_active_picked.iloc[:, 0],\n",
    "                                   CF_model[\"predicted_rating\"]))\n",
    "            kumpulan_rmse.append(rms)\n",
    "            print(f\"Nilai RMSEnya adalah:\\t{rms}\\n\")\n",
    "        print(f\"ini nilai i: {i}\")\n",
    "\n",
    "    mean_dari_mean_rmse_kuintil.append(np.mean(kumpulan_rmse))\n",
    "    panjang_kumpulan_rmse_kuintil.append(len(kumpulan_rmse))\n",
    "    kumpulan_dari_kumpulan_waktu_kuintil.append((time.time() - start_time)-w_awal)\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (kumpulan_dari_kumpulan_waktu_kuintil[kuintil]))\n",
    "    print(f\"ini adalah meannya dan len-nya:\\t{mean_dari_mean_rmse_kuintil[kuintil]};\\t{panjang_kumpulan_rmse_kuintil[kuintil]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d803edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w_awal)\n",
    "print(mean_dari_mean_rmse_kuintil)\n",
    "print(panjang_kumpulan_rmse_kuintil)\n",
    "print(kumpulan_dari_kumpulan_waktu_kuintil)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
